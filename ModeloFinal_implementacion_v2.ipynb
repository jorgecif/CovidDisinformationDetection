{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFM-ModeloFinal_implementacion_v2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOOhcf/DT8ULqDeY2slfeNX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jorgecif/CovidDisinformationDetection/blob/main/ModeloFinal_implementacion_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-sjukMkc3iY"
      },
      "source": [
        "# **Detección de desinformación relacionada con COVID19** - implementacion\n",
        "\n",
        "> Por: Jorge Orlando Cifuentes Cifuentes\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2j64mpxhBTe"
      },
      "source": [
        "Componentes principales:\n",
        "\n",
        "\n",
        "*   Carga de modelos\n",
        "*   Prueba\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKlTx3vWrlWC"
      },
      "source": [
        "### Librerías y funciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIEkgmbsrqd_",
        "outputId": "4d7179de-c3df-4a18-9d9f-7193c48aaf21"
      },
      "source": [
        "# Generales\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#import csv\n",
        "#import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, joblib # Para exportar el modelo\n",
        "from io import BytesIO\n",
        "import requests\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "# Gráficas\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Machine learning\n",
        "from keras.layers import concatenate\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D, LSTM\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, Activation, Flatten, Bidirectional\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "# Procesamiento lenguaje natural\n",
        "\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS, preprocess_string, strip_punctuation, strip_numeric\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "np.random.seed(88)\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhsRTi2Gt-US"
      },
      "source": [
        "### Carga de modelos "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mwZh0TfuCQQ"
      },
      "source": [
        "# Modelos temática\n",
        "\n",
        "mLink = 'https://github.com/jorgecif/CovidDisinformationDetection/blob/main/TrainedModels/Modelo_PrediccionTema/Tema_ML_vectorizer.pkl?raw=true'\n",
        "mfile = BytesIO(requests.get(mLink).content)\n",
        "vectorizer = joblib.load(mfile)\n",
        "\n",
        "mLink = 'https://github.com/jorgecif/CovidDisinformationDetection/blob/main/TrainedModels/Modelo_PrediccionTema/Tema_ML_RF_model.pkl?raw=true'\n",
        "mfile = BytesIO(requests.get(mLink).content)\n",
        "rf_mod = joblib.load(mfile)\n",
        "\n",
        "mLink = 'https://github.com/jorgecif/CovidDisinformationDetection/blob/main/TrainedModels/Modelo_PrediccionTema/Tema_ML_LOG_model.pkl?raw=true'\n",
        "mfile = BytesIO(requests.get(mLink).content)\n",
        "log_mod = joblib.load(mfile)\n",
        "\n",
        "# Modelo LDA subtemática\n",
        "mLink = 'https://github.com/jorgecif/CovidDisinformationDetection/blob/main/TrainedModels/Modelo_Subtema/model_LDA.pkl?raw=true'\n",
        "mfile = BytesIO(requests.get(mLink).content)\n",
        "model_lda_cargado = joblib.load(mfile)\n",
        "\n",
        "mLink = 'https://github.com/jorgecif/CovidDisinformationDetection/blob/main/TrainedModels/Modelo_Subtema/dictionary.pkl?raw=true'\n",
        "mfile = BytesIO(requests.get(mLink).content)\n",
        "dictionary_cargado = joblib.load(mfile)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mt3qf1MRVKC"
      },
      "source": [
        "# Modelo LSTM final\r\n",
        "mLink = 'https://github.com/jorgecif/CovidDisinformationDetection/blob/main/TrainedModels/Modelo_FinalUnificado/tokenizer_base.pkl?raw=true'\r\n",
        "mfile = BytesIO(requests.get(mLink).content)\r\n",
        "tokenizer_base = joblib.load(mfile)\r\n",
        "\r\n",
        "mLink = 'https://github.com/jorgecif/CovidDisinformationDetection/blob/main/TrainedModels/Modelo_FinalUnificado/tokenizer.pkl?raw=true'\r\n",
        "mfile = BytesIO(requests.get(mLink).content)\r\n",
        "tokenizer = joblib.load(mfile)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJhA0U8nWC8m",
        "outputId": "4c145974-72b1-4262-ec6e-74a7ba775136"
      },
      "source": [
        "# Carga de modelos h5 desde github\r\n",
        "\r\n",
        "import urllib.request\r\n",
        "\r\n",
        "urllib.request.urlretrieve(\r\n",
        "        'https://github.com/jorgecif/CovidDisinformationDetection/blob/main/TrainedModels/Modelo_FinalUnificado/model_base_1input.h5?raw=true', 'model_base.h5')\r\n",
        "\r\n",
        "urllib.request.urlretrieve(\r\n",
        "        'https://github.com/jorgecif/CovidDisinformationDetection/blob/main/TrainedModels/Modelo_FinalUnificado/model_LSTM_1input.h5?raw=true', 'model_lstm1.h5')\r\n",
        "\r\n",
        "urllib.request.urlretrieve(\r\n",
        "        'https://github.com/jorgecif/CovidDisinformationDetection/blob/main/TrainedModels/Modelo_FinalUnificado/modelLSTM_2inputs.h5?raw=true', 'model_lstm2.h5')\r\n",
        "\r\n",
        "urllib.request.urlretrieve(\r\n",
        "        'https://github.com/jorgecif/CovidDisinformationDetection/blob/main/TrainedModels/Modelo_FinalUnificado/model_biLSTM_2inputs.h5?raw=true', 'model_lstm2_2.h5')\r\n",
        "\r\n",
        "model_base = tf.keras.models.load_model('content/model_base.h5')\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('model_lstm2_2.h5', <http.client.HTTPMessage at 0x7fdb2af7f470>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is9bEvb0pReg"
      },
      "source": [
        "model_base = tf.keras.models.load_model('model_base.h5')\r\n",
        "model_lstm1 = tf.keras.models.load_model('model_lstm1.h5')\r\n",
        "model_lstm2 = tf.keras.models.load_model('model_lstm2.h5')\r\n",
        "model_lstm2_2 = tf.keras.models.load_model('model_lstm2_2.h5')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioAfODyIzk-u",
        "outputId": "058dcbf5-1dbb-47c4-82c4-54840844a759"
      },
      "source": [
        "# Muestro algunos de los modelos cargados\n",
        "print(vectorizer)\n",
        "print(log_mod)\n",
        "print(tokenizer)\n",
        "print(model_base)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
            "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
            "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
            "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                tokenizer=None, vocabulary=None)\n",
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "<keras_preprocessing.text.Tokenizer object at 0x7fdb2cd3df60>\n",
            "<tensorflow.python.keras.engine.sequential.Sequential object at 0x7fdb2aa34fd0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuXq9YAZC58i"
      },
      "source": [
        "#### Texto a revisar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0MrIxUnC72V"
      },
      "source": [
        "# Calculo predicciones de modelos con función\r\n",
        "\r\n",
        "texto_a_revisar=\"You can protect yourself from COVID-19 by injecting, swallowing, bathing in or rubbing onto your body bleach, disinfectants or rubbing alcohols\"\r\n",
        "#texto_a_revisar=\"Bill Gates told us about the coronavirus in 2015\"\r\n",
        "#texto_a_revisar=\"Turmeric And Lemon Help Fight Against coronavirus.\"\r\n",
        "#texto_a_revisar=\"Uganda is giving out 122GB of data to customers for free in response to COVID-19\"\r\n",
        "#texto_a_revisar=\"What we need to do to defeat the coronavirus is to consume more alkaline foods above the virus’ pH level\"\r\n",
        "#CANADA'S TRUDEAU SAYS WHOLE NATION FRUSTRATED BY SLOW PACE OF CORONAVIRUS VACCINATIONS\r\n",
        "#WHO's Tedros 'very disappointed' China hasn't granted entry to coronavirus experts\r\n",
        "#Zimbabwe daily COVID-19 cases jump to 1,365 as extended lockdown starts\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACYtFutvDkC0"
      },
      "source": [
        "### Aplico modelo para clasficar la temática"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNhJ_mOsvZzR"
      },
      "source": [
        "# Función para aplicar modelo\r\n",
        "def aplicar_modelo(datos_revisar, tokenizador, modelo):\r\n",
        "  tokenizador=tokenizador\r\n",
        "  modelo=modelo\r\n",
        "  datos_revisar=datos_revisar\r\n",
        "  linea_revisar_token=tokenizador.transform([datos_revisar])\r\n",
        "  resultado=modelo.predict(linea_revisar_token)\r\n",
        "  return resultado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPFLZ89FDF2X"
      },
      "source": [
        "# Aplico modelo\r\n",
        "pred_model_clasifica=aplicar_modelo(texto_a_revisar, vectorizer, log_mod)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehIbeCoAwBoG",
        "outputId": "ddf61310-945e-4298-c3d8-625bcc9eb7d3"
      },
      "source": [
        "pred_model_clasifica"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lucl9wT58YZE"
      },
      "source": [
        "# Labels del tema\r\n",
        "def get_keys(val,my_dict):\r\n",
        "    for key, value in my_dict.items():\r\n",
        "        if val == value:\r\n",
        "            return key\r\n",
        "\r\n",
        "tema_labels = {\"Health\":0, \"Enviroment\":1, \"Lifestyle\":2, \"Finance\":3, \"Sports\":4, \"Politics\":5, \"Technology\":6, \"Science\":7}\r\n",
        "prediction_tema_label = get_keys(pred_model_clasifica,tema_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "faT34cef8YVP",
        "outputId": "aec525c0-bfe2-465e-a51d-2d5076f4f56c"
      },
      "source": [
        "prediction_tema_label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Health'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4hoUfmNCXSW"
      },
      "source": [
        "### Aplico modelo para extraer la subtemática y palabras claves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAJyKkz88xs9"
      },
      "source": [
        "# Convertir palabras plural en singular\r\n",
        "stemmer = SnowballStemmer(\"english\")\r\n",
        "original_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \r\n",
        "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \r\n",
        "           'traditional', 'reference', 'colonizer','plotted']\r\n",
        "singles = [stemmer.stem(plural) for plural in original_words]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPVLXshOEytV"
      },
      "source": [
        "# Preprocesamiento\r\n",
        "\r\n",
        "def lemmatize_stemming(text):\r\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\r\n",
        "# Tokenize and lemmatize\r\n",
        "def preprocess(text):\r\n",
        "    result=[]\r\n",
        "    for token in gensim.utils.simple_preprocess(text) :\r\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\r\n",
        "            result.append(lemmatize_stemming(token))\r\n",
        "            \r\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_0ChhV1Di21",
        "outputId": "09094a58-b496-4cd6-f805-081468d72968"
      },
      "source": [
        "# Muestro los temas creados\r\n",
        "\r\n",
        "for idx, topic in model_lda_cargado.print_topics(-1):\r\n",
        "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\r\n",
        "    print(\"\\n\")\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 \n",
            "Words: 0.017*\"test\" + 0.013*\"health\" + 0.011*\"australia\" + 0.009*\"travel\" + 0.009*\"clinic\" + 0.008*\"flight\" + 0.008*\"govern\" + 0.008*\"window\" + 0.008*\"hospit\" + 0.008*\"set\"\n",
            "\n",
            "\n",
            "Topic: 1 \n",
            "Words: 0.022*\"facebook\" + 0.021*\"post\" + 0.021*\"toilet\" + 0.020*\"paper\" + 0.018*\"show\" + 0.017*\"share\" + 0.014*\"novel\" + 0.011*\"lockdown\" + 0.010*\"thousand\" + 0.010*\"photo\"\n",
            "\n",
            "\n",
            "Topic: 2 \n",
            "Words: 0.014*\"infect\" + 0.010*\"pictur\" + 0.009*\"health\" + 0.008*\"spread\" + 0.007*\"case\" + 0.007*\"diseas\" + 0.007*\"mask\" + 0.007*\"countri\" + 0.006*\"report\" + 0.006*\"hand\"\n",
            "\n",
            "\n",
            "Topic: 3 \n",
            "Words: 0.026*\"case\" + 0.016*\"outbreak\" + 0.012*\"confirm\" + 0.012*\"state\" + 0.012*\"death\" + 0.011*\"trump\" + 0.010*\"health\" + 0.010*\"citi\" + 0.009*\"chines\" + 0.008*\"infect\"\n",
            "\n",
            "\n",
            "Topic: 4 \n",
            "Words: 0.025*\"health\" + 0.018*\"australia\" + 0.014*\"case\" + 0.013*\"test\" + 0.013*\"hospit\" + 0.011*\"public\" + 0.009*\"travel\" + 0.008*\"offic\" + 0.007*\"chief\" + 0.007*\"patient\"\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYBBb_k2EFop",
        "outputId": "328ff56b-ca82-4647-a197-d385da61f765"
      },
      "source": [
        "# Recuento de palabras de topics\r\n",
        "num_words=10\r\n",
        "\r\n",
        "lda_topics_cargados = model_lda_cargado.show_topics(num_words=num_words)\r\n",
        "topics_cargados = []\r\n",
        "filters = [lambda x: x.lower(), strip_punctuation, strip_numeric]\r\n",
        "\r\n",
        "for topic in lda_topics_cargados:\r\n",
        "    topics_cargados.append(preprocess_string(topic[1], filters))\r\n",
        "topics_cargados"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['test',\n",
              "  'health',\n",
              "  'australia',\n",
              "  'travel',\n",
              "  'clinic',\n",
              "  'flight',\n",
              "  'govern',\n",
              "  'window',\n",
              "  'hospit',\n",
              "  'set'],\n",
              " ['facebook',\n",
              "  'post',\n",
              "  'toilet',\n",
              "  'paper',\n",
              "  'show',\n",
              "  'share',\n",
              "  'novel',\n",
              "  'lockdown',\n",
              "  'thousand',\n",
              "  'photo'],\n",
              " ['infect',\n",
              "  'pictur',\n",
              "  'health',\n",
              "  'spread',\n",
              "  'case',\n",
              "  'diseas',\n",
              "  'mask',\n",
              "  'countri',\n",
              "  'report',\n",
              "  'hand'],\n",
              " ['case',\n",
              "  'outbreak',\n",
              "  'confirm',\n",
              "  'state',\n",
              "  'death',\n",
              "  'trump',\n",
              "  'health',\n",
              "  'citi',\n",
              "  'chines',\n",
              "  'infect'],\n",
              " ['health',\n",
              "  'australia',\n",
              "  'case',\n",
              "  'test',\n",
              "  'hospit',\n",
              "  'public',\n",
              "  'travel',\n",
              "  'offic',\n",
              "  'chief',\n",
              "  'patient']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsteCT8lGoRO"
      },
      "source": [
        "# Función para aplicar modelo\r\n",
        "\r\n",
        "def aplicar_lda(documento): \r\n",
        "    unseen_document=documento\r\n",
        "    # Preprocesamiento\r\n",
        "    bow_vector = dictionary_cargado.doc2bow(preprocess(unseen_document))\r\n",
        "    # Aplico modelo\r\n",
        "    prediction_lda=model_lda_cargado[bow_vector]\r\n",
        "\r\n",
        "    probs=[]\r\n",
        "    for i in range(0, len(prediction_lda)):\r\n",
        "        probs.append(prediction_lda[i][1])\r\n",
        "    max_probs=max(probs)\r\n",
        "\r\n",
        "    position=[]\r\n",
        "    for i in range(0,len(prediction_lda)):\r\n",
        "        if max_probs==prediction_lda[i][1]:\r\n",
        "            position=i\r\n",
        "            break\r\n",
        "    result=prediction_lda[position][0]\r\n",
        "    \r\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3dY1U0_GtCo"
      },
      "source": [
        "pred=aplicar_lda(texto_a_revisar)\r\n",
        "words_topics_lda=str(topics_cargados[pred])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "e1_z3RI0IDFS",
        "outputId": "6b66184c-dd0a-4f76-bc89-31958e830ef6"
      },
      "source": [
        "words_topics_lda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"['infect', 'pictur', 'health', 'spread', 'case', 'diseas', 'mask', 'countri', 'report', 'hand']\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnRBU1_5HX3Y"
      },
      "source": [
        "# Creo dataframe con columna adicional de predicción\n",
        "datos_trabajo_pred=datos_trabajo\n",
        "datos_trabajo_pred[\"pred_clasifica\"]=pred_model_clasifica"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TSno2ONQLzr"
      },
      "source": [
        "#### Concateno resultados para que sirvan como entrada de modelo unificado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bghO1SKiP3FF"
      },
      "source": [
        "# Datos de texto = INPUT 1\r\n",
        "datos_analizar_texto=words_topics_lda+texto_a_revisar\r\n",
        "input1=datos_analizar_texto"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G-e7Q4ASvn0"
      },
      "source": [
        "# Datos numéricos = INPUT 2\r\n",
        "\r\n",
        "metadatos=[np.asarray(pred_model_clasifica[0]).astype(np.int32),np.asarray(pred).astype(np.int32)]\r\n",
        "metadatos=np.asarray(metadatos).astype(np.int32)\r\n",
        "input2=[]\r\n",
        "input2.append(metadatos)  \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXECfV8wjaz6",
        "outputId": "475372f2-ef40-4ccf-ccde-eaa2b64a1ccc"
      },
      "source": [
        "input2[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q7WgBsRgeUy",
        "outputId": "68a73b90-e781-46c1-ad19-7ce21bd221b8"
      },
      "source": [
        "input2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKv4GNGpMN0e"
      },
      "source": [
        "### Aplico modelo unificado LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho39YDKBYFUt"
      },
      "source": [
        "# Parámetros\r\n",
        "\r\n",
        "# Tokenizador\r\n",
        "tokenizer1input=tokenizer_base #Tokenizer para modelo sencillo\r\n",
        "tokenizer2input=tokenizer #Tokenizer para modelo de 2 entradas\r\n",
        "\r\n",
        "# Parámetros tokenizador\r\n",
        "n_most_common_words = 10000\r\n",
        "max_len = 300\r\n",
        "\r\n",
        "# Modelos\r\n",
        "# model_base = modelo base \r\n",
        "# model_lstm1 = modelo lstm 1 entrada\r\n",
        "# model_lstm2 = modelo lstm 2 entradas\r\n",
        "# model_lstm2_2 = modelo lstm bidireccional 2 entradas\r\n",
        "\r\n",
        "# Entradas\r\n",
        "texto_inicial=texto_a_revisar\r\n",
        "# input1: entrada 1 texto original + palabras clave de subtema\r\n",
        "# input2: entrada 2 metadatos tema, subtema\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyVOcgpvb5jP"
      },
      "source": [
        "# Predicción modelo base 1 entrada\r\n",
        "test=texto_a_revisar\r\n",
        "\r\n",
        "corpus_t=[]\r\n",
        "corpus_t.append(test)\r\n",
        "corpus_t=pd.Series(corpus_t)\r\n",
        "  \r\n",
        "sequences_reserva = tokenizer_base.texts_to_sequences(corpus_t.values)\r\n",
        "transform_vect_reserva1= pad_sequences(sequences_reserva, maxlen=max_len)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut7DffCUdFQg",
        "outputId": "64dfb3cd-e8d0-43f5-ded2-14c206b22ff0"
      },
      "source": [
        "# Predicción\r\n",
        "prediccion_base=model_base.predict(transform_vect_reserva1)\r\n",
        "prediccion_base\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.07467994]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr_Lrxnmb5f7"
      },
      "source": [
        "# Predicción modelo lstm 2 entradas\r\n",
        "entrada1=input1\r\n",
        "entrada2=input2\r\n",
        "entrada2_arr=np.array(entrada2) # cambio a array para pasar al modelo\r\n",
        "\r\n",
        "# Preparación\r\n",
        "corpus_t=[]\r\n",
        "corpus_t.append(entrada1)\r\n",
        "corpus_t=pd.Series(corpus_t)\r\n",
        "  \r\n",
        "sequences_reserva = tokenizer.texts_to_sequences(corpus_t.values)\r\n",
        "transform_vect_reserva2= pad_sequences(sequences_reserva, maxlen=max_len)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugTn9GOidCFf",
        "outputId": "c359c7e1-d02c-4844-953c-b9ace9b091d9"
      },
      "source": [
        "# Predicción\r\n",
        "\r\n",
        "#prediccion_lstm2=model_lstm2.predict([transform_vect_reserva2,input2])\r\n",
        "#prediccion_lstm2=model_lstm2.predict(transform_vect_reserva2)\r\n",
        "prediccion_lstm2=model_lstm2.predict({'nlp_input': transform_vect_reserva2, 'meta_input': entrada2_arr})\r\n",
        "prediccion_lstm2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.3192422e-06]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe5QwwVilF3O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5IsTzNeVkH2"
      },
      "source": [
        "# Función para prueba de predicciones 1 entrada\r\n",
        "\r\n",
        "def aplicar_modelo_unif_1input(a, modelo_probar, tokenizer):\r\n",
        "    clf=modelo_probar\r\n",
        "    tok=tokenizer\r\n",
        "    # Tokenizacion\r\n",
        "    corpus_1=[]\r\n",
        "    corpus_1.append(a)\r\n",
        "    corpus_2=pd.Series(corpus_1)\r\n",
        "    sequences_reserva = tok.texts_to_sequences(corpus_2.values)\r\n",
        "    transform_vect_reserva= pad_sequences(sequences_reserva, maxlen=max_len)\r\n",
        "    prediccion=clf.predict(transform_vect_reserva)\r\n",
        "    prediccion_a = [np.array(prediccion)]\r\n",
        "    if prediccion > 0.5:\r\n",
        "      label= \"NO\"\r\n",
        "    else:\r\n",
        "      label = \"SI\"\r\n",
        "    alerta=[prediccion,label]\r\n",
        "    return alerta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QoK0A35VkEv",
        "outputId": "033fbb5f-7c8a-4ea7-91be-c3f366eea92c"
      },
      "source": [
        "# Prueba con función modelos 1 entrada\r\n",
        "\r\n",
        "clasificar_texto=texto_a_revisar\r\n",
        "\r\n",
        "resultado_prediccion=aplicar_modelo_unif_1input(clasificar_texto, model_base, tokenizer_base)\r\n",
        "\r\n",
        "print(\"Texto: \", clasificar_texto)\r\n",
        "print(\" \")\r\n",
        "print(\"Predicción: \")\r\n",
        "print(\"Alerta de desinformación: \", resultado_prediccion[1]) \r\n",
        "print(\"Probabilidad asociada: \", resultado_prediccion[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto:  You can protect yourself from COVID-19 by injecting, swallowing, bathing in or rubbing onto your body bleach, disinfectants or rubbing alcohols\n",
            " \n",
            "Predicción: \n",
            "Alerta de desinformación:  SI\n",
            "Probabilidad asociada:  [0.07467994]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9rvc5VJm3gq"
      },
      "source": [
        "# Función para prueba de predicciones 2 entradas\r\n",
        "\r\n",
        "def aplicar_modelo_unif_2input(in1, in2, modelo_probar, tokenizer):\r\n",
        "    clf=modelo_probar\r\n",
        "    tok=tokenizer\r\n",
        "    # Tokenizacion\r\n",
        "    corpus_1=[]\r\n",
        "    corpus_1.append(in1)\r\n",
        "    corpus_2=pd.Series(corpus_1)\r\n",
        "    sequences_reserva = tok.texts_to_sequences(corpus_2.values)\r\n",
        "    in2_arr=np.array(in2) # cambio a array para pasar al modelo\r\n",
        "    transform_vect_reserva= pad_sequences(sequences_reserva, maxlen=max_len)\r\n",
        "    prediccion=clf.predict({'nlp_input': transform_vect_reserva, 'meta_input': in2_arr})    \r\n",
        "    prediccion_a = [np.array(prediccion)]\r\n",
        "    if prediccion > 0.5:\r\n",
        "      label= \"NO\"\r\n",
        "    else:\r\n",
        "      label = \"SI\"\r\n",
        "    alerta=[prediccion,label]\r\n",
        "    return alerta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CDnbfPnm3eT",
        "outputId": "936db34a-b75d-494c-f513-eadc88211486"
      },
      "source": [
        "# Aplico el modelo\r\n",
        "\r\n",
        "in1=entrada1\r\n",
        "in2=entrada2\r\n",
        "\r\n",
        "resultado_prediccion_2=aplicar_modelo_unif_2input(in1, in2, model_lstm2, tokenizer)\r\n",
        "\r\n",
        "print(\"Texto: \", clasificar_texto)\r\n",
        "print(\" \")\r\n",
        "print(\"Predicción: \")\r\n",
        "print(\"Alerta de desinformación: \", resultado_prediccion_2[1]) \r\n",
        "print(\"Probabilidad asociada: \", resultado_prediccion_2[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto:  You can protect yourself from COVID-19 by injecting, swallowing, bathing in or rubbing onto your body bleach, disinfectants or rubbing alcohols\n",
            " \n",
            "Predicción: \n",
            "Alerta de desinformación:  SI\n",
            "Probabilidad asociada:  [1.3192422e-06]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWfElMGwm3bd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNUZ9NPAWxLg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}